{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccb3ddc-a4f3-400b-b42d-53365d10f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:12:51.267398: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-29 13:12:51.306248: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-29 13:12:51.307215: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-29 13:12:52.012225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.modules.data_loader import create_ffn_dataset\n",
    "from src.modules.training_utils import train_ffn\n",
    "from src.models.fnn import build_ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55978bbb-3198-49d7-b751-cbe87dc56416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "tfrecord_file = \"../data/FFNs/FFNs_init.tfrecord\"\n",
    "\n",
    "# Input parameters\n",
    "max_atoms = 7662 # Required for fixed sized FNN\n",
    "input_geometry_shape = (max_atoms, 3)  # Example geometry shape\n",
    "input_frequency_shape = (1,)\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28555ab6-d9ef-417c-9cae-50dd30b9b494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = create_ffn_dataset(tfrecord_file, batch_size=batch_size)\n",
    "print(\"Dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca924ba-a850-4a40-9758-3620e35768ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model: \"GraphAIne_FFN_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " geometry_input (InputLayer  [(None, 7662, 3)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 7662, 64)             640       ['geometry_input[0][0]']      \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 7662, 128)            24704     ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " frequency_input (InputLaye  [(None, 1)]                  0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['conv1d_1[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   64        ['frequency_input[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  33024     ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 16)                   528       ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 272)                  0         ['dense[0][0]',               \n",
      "                                                                     'dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  34944     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 64)                   8256      ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 45972)                2988180   ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 7662, 6)              0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3090340 (11.79 MB)\n",
      "Trainable params: 3090340 (11.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "print(\"Building model...\")\n",
    "model = build_ffn(input_geometry_shape, input_frequency_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e793555-6cc2-46e7-b835-18a6957d9f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "ðŸš€ Epoch 1/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 534.9943237304688\n",
      "Step 10, Loss: 58.2905158996582\n",
      "Step 20, Loss: 30.57242774963379\n",
      "Step 30, Loss: 20.72539710998535\n",
      "Step 40, Loss: 15.680622100830078\n",
      "Step 50, Loss: 12.61393928527832\n",
      "Step 60, Loss: 10.552964210510254\n",
      "Step 70, Loss: 9.072209358215332\n",
      "Step 80, Loss: 7.957249641418457\n",
      "Step 90, Loss: 7.087714672088623\n",
      "Step 100, Loss: 6.390305519104004\n",
      "Step 110, Loss: 5.818028926849365\n",
      "Step 120, Loss: 5.340300559997559\n",
      "Step 130, Loss: 4.936929702758789\n",
      "Step 140, Loss: 4.595702648162842\n",
      "Step 150, Loss: 4.302095413208008\n",
      "Step 160, Loss: 4.044480800628662\n",
      "Step 170, Loss: 3.818225622177124\n",
      "Step 180, Loss: 3.6201014518737793\n",
      "Step 190, Loss: 3.4410712718963623\n",
      "Step 200, Loss: 3.280712604522705\n",
      "Step 210, Loss: 3.1347827911376953\n",
      "Step 220, Loss: 3.004272937774658\n",
      "Step 230, Loss: 2.88201642036438\n",
      "Step 240, Loss: 2.771798849105835\n",
      "Step 250, Loss: 2.671610116958618\n",
      "Step 260, Loss: 2.5782363414764404\n",
      "Step 270, Loss: 2.490475654602051\n",
      "Step 280, Loss: 2.409893274307251\n",
      "Step 290, Loss: 2.335465431213379\n",
      "Step 300, Loss: 2.267728328704834\n",
      "Step 310, Loss: 2.2100636959075928\n",
      "Step 320, Loss: 2.151776075363159\n",
      "Step 330, Loss: 2.09920597076416\n",
      "Step 340, Loss: 2.0504276752471924\n",
      "Step 350, Loss: 2.004703998565674\n",
      "Step 360, Loss: 1.9620124101638794\n",
      "Step 370, Loss: 1.9231666326522827\n",
      "Step 380, Loss: 1.886178731918335\n",
      "Step 390, Loss: 1.8501076698303223\n",
      "Step 400, Loss: 1.8147876262664795\n",
      "Step 410, Loss: 1.7797417640686035\n",
      "Step 420, Loss: 1.748152256011963\n",
      "Step 430, Loss: 1.7187341451644897\n",
      "Step 440, Loss: 1.6884454488754272\n",
      "Step 450, Loss: 1.6600593328475952\n",
      "Step 460, Loss: 1.6330454349517822\n",
      "Step 470, Loss: 1.605197787284851\n",
      "Step 480, Loss: 1.5779577493667603\n",
      "Step 490, Loss: 1.551918387413025\n",
      "Step 500, Loss: 1.5267044305801392\n",
      "Step 510, Loss: 1.5025264024734497\n",
      "Step 520, Loss: 1.4780850410461426\n",
      "Step 530, Loss: 1.4550186395645142\n",
      "Step 540, Loss: 1.433154821395874\n",
      "Step 550, Loss: 1.412102460861206\n",
      "Step 560, Loss: 1.3920129537582397\n",
      "Step 570, Loss: 1.3722097873687744\n",
      "Step 580, Loss: 1.3532484769821167\n",
      "Step 590, Loss: 1.3350902795791626\n",
      "Step 600, Loss: 1.3175767660140991\n",
      "Step 610, Loss: 1.300905704498291\n",
      "Step 620, Loss: 1.2845176458358765\n",
      "Step 630, Loss: 1.2682442665100098\n",
      "Step 640, Loss: 1.252923607826233\n",
      "Step 650, Loss: 1.237323522567749\n",
      "Step 660, Loss: 1.2224178314208984\n",
      "Step 670, Loss: 1.2079800367355347\n",
      "Step 680, Loss: 1.193713903427124\n",
      "Step 690, Loss: 1.179829716682434\n",
      "Step 700, Loss: 1.1665815114974976\n",
      "Step 710, Loss: 1.1536202430725098\n",
      "Step 720, Loss: 1.1413483619689941\n",
      "Step 730, Loss: 1.129569411277771\n",
      "Step 740, Loss: 1.1174997091293335\n",
      "Step 750, Loss: 1.1056616306304932\n",
      "Step 760, Loss: 1.0936765670776367\n",
      "Step 770, Loss: 1.0824475288391113\n",
      "Step 780, Loss: 1.0709234476089478\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-1\n",
      "\n",
      "ðŸš€ Epoch 2/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04111180454492569\n",
      "Step 10, Loss: 0.04040559008717537\n",
      "Step 20, Loss: 0.04264915734529495\n",
      "Step 30, Loss: 0.04269726946949959\n",
      "Step 40, Loss: 0.042214248329401016\n",
      "Step 50, Loss: 0.04250413924455643\n",
      "Step 60, Loss: 0.042625997215509415\n",
      "Step 70, Loss: 0.042253877967596054\n",
      "Step 80, Loss: 0.04217328131198883\n",
      "Step 90, Loss: 0.04281722754240036\n",
      "Step 100, Loss: 0.042610250413417816\n",
      "Step 110, Loss: 0.04261557012796402\n",
      "Step 120, Loss: 0.04220033437013626\n",
      "Step 130, Loss: 0.044586509466171265\n",
      "Step 140, Loss: 0.04821838438510895\n",
      "Step 150, Loss: 0.05428938940167427\n",
      "Step 160, Loss: 0.061091192066669464\n",
      "Step 170, Loss: 0.06878714263439178\n",
      "Step 180, Loss: 0.07692013680934906\n",
      "Step 190, Loss: 0.08461536467075348\n",
      "Step 200, Loss: 0.09066314995288849\n",
      "Step 210, Loss: 0.09589733928442001\n",
      "Step 220, Loss: 0.10159303992986679\n",
      "Step 230, Loss: 0.10680229961872101\n",
      "Step 240, Loss: 0.11175703257322311\n",
      "Step 250, Loss: 0.11697279661893845\n",
      "Step 260, Loss: 0.12040604650974274\n",
      "Step 270, Loss: 0.12233849614858627\n",
      "Step 280, Loss: 0.12627068161964417\n",
      "Step 290, Loss: 0.1312250941991806\n",
      "Step 300, Loss: 0.1374349296092987\n",
      "Step 310, Loss: 0.14409318566322327\n",
      "Step 320, Loss: 0.15154291689395905\n",
      "Step 330, Loss: 0.1614377796649933\n",
      "Step 340, Loss: 0.16955234110355377\n",
      "Step 350, Loss: 0.17760269343852997\n",
      "Step 360, Loss: 0.18675535917282104\n",
      "Step 370, Loss: 0.19438070058822632\n",
      "Step 380, Loss: 0.20354533195495605\n",
      "Step 390, Loss: 0.20906919240951538\n",
      "Step 400, Loss: 0.21411705017089844\n",
      "Step 410, Loss: 0.21980293095111847\n",
      "Step 420, Loss: 0.2250020056962967\n",
      "Step 430, Loss: 0.2307726889848709\n",
      "Step 440, Loss: 0.23533594608306885\n",
      "Step 450, Loss: 0.23922578990459442\n",
      "Step 460, Loss: 0.2411968857049942\n",
      "Step 470, Loss: 0.24268850684165955\n",
      "Step 480, Loss: 0.24430334568023682\n",
      "Step 490, Loss: 0.24505829811096191\n",
      "Step 500, Loss: 0.24661824107170105\n",
      "Step 510, Loss: 0.24711892008781433\n",
      "Step 520, Loss: 0.24682150781154633\n",
      "Step 530, Loss: 0.24628619849681854\n",
      "Step 540, Loss: 0.24631530046463013\n",
      "Step 550, Loss: 0.24695447087287903\n",
      "Step 560, Loss: 0.24725483357906342\n",
      "Step 570, Loss: 0.24849146604537964\n",
      "Step 580, Loss: 0.2485453188419342\n",
      "Step 590, Loss: 0.2495923787355423\n",
      "Step 600, Loss: 0.250095009803772\n",
      "Step 610, Loss: 0.2506980299949646\n",
      "Step 620, Loss: 0.2513168454170227\n",
      "Step 630, Loss: 0.2515537738800049\n",
      "Step 640, Loss: 0.2511925995349884\n",
      "Step 650, Loss: 0.25099557638168335\n",
      "Step 660, Loss: 0.25115200877189636\n",
      "Step 670, Loss: 0.2512107789516449\n",
      "Step 680, Loss: 0.25101587176322937\n",
      "Step 690, Loss: 0.2506239414215088\n",
      "Step 700, Loss: 0.25080394744873047\n",
      "Step 710, Loss: 0.2508450150489807\n",
      "Step 720, Loss: 0.2510150671005249\n",
      "Step 730, Loss: 0.2510017454624176\n",
      "Step 740, Loss: 0.25088340044021606\n",
      "Step 750, Loss: 0.25081902742385864\n",
      "Step 760, Loss: 0.250078409910202\n",
      "Step 770, Loss: 0.24969325959682465\n",
      "Step 780, Loss: 0.24913179874420166\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-2\n",
      "\n",
      "ðŸš€ Epoch 3/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04894527420401573\n",
      "Step 10, Loss: 0.043409563601017\n",
      "Step 20, Loss: 0.04296336695551872\n",
      "Step 30, Loss: 0.04435253143310547\n",
      "Step 40, Loss: 0.04372778907418251\n",
      "Step 50, Loss: 0.04310842230916023\n",
      "Step 60, Loss: 0.043001145124435425\n",
      "Step 70, Loss: 0.04257144778966904\n",
      "Step 80, Loss: 0.04208159074187279\n",
      "Step 90, Loss: 0.04281560704112053\n",
      "Step 100, Loss: 0.04274800792336464\n",
      "Step 110, Loss: 0.042536936700344086\n",
      "Step 120, Loss: 0.04223627597093582\n",
      "Step 130, Loss: 0.0442773774266243\n",
      "Step 140, Loss: 0.0500531829893589\n",
      "Step 150, Loss: 0.05706094205379486\n",
      "Step 160, Loss: 0.06183210760354996\n",
      "Step 170, Loss: 0.0684846043586731\n",
      "Step 180, Loss: 0.0770101547241211\n",
      "Step 190, Loss: 0.08498270809650421\n",
      "Step 200, Loss: 0.09105634689331055\n",
      "Step 210, Loss: 0.09554918110370636\n",
      "Step 220, Loss: 0.09997187554836273\n",
      "Step 230, Loss: 0.10445931553840637\n",
      "Step 240, Loss: 0.11015564203262329\n",
      "Step 250, Loss: 0.11603086441755295\n",
      "Step 260, Loss: 0.11981266736984253\n",
      "Step 270, Loss: 0.1226302832365036\n",
      "Step 280, Loss: 0.12529441714286804\n",
      "Step 290, Loss: 0.1293506771326065\n",
      "Step 300, Loss: 0.13669316470623016\n",
      "Step 310, Loss: 0.14455977082252502\n",
      "Step 320, Loss: 0.1527862250804901\n",
      "Step 330, Loss: 0.16099520027637482\n",
      "Step 340, Loss: 0.16749665141105652\n",
      "Step 350, Loss: 0.1757868081331253\n",
      "Step 360, Loss: 0.18519467115402222\n",
      "Step 370, Loss: 0.1953956037759781\n",
      "Step 380, Loss: 0.20387324690818787\n",
      "Step 390, Loss: 0.20971961319446564\n",
      "Step 400, Loss: 0.21510502696037292\n",
      "Step 410, Loss: 0.2213270515203476\n",
      "Step 420, Loss: 0.22706207633018494\n",
      "Step 430, Loss: 0.23150652647018433\n",
      "Step 440, Loss: 0.23643362522125244\n",
      "Step 450, Loss: 0.23876658082008362\n",
      "Step 460, Loss: 0.24177610874176025\n",
      "Step 470, Loss: 0.2438795566558838\n",
      "Step 480, Loss: 0.24507778882980347\n",
      "Step 490, Loss: 0.2461232990026474\n",
      "Step 500, Loss: 0.24649187922477722\n",
      "Step 510, Loss: 0.24724777042865753\n",
      "Step 520, Loss: 0.24728193879127502\n",
      "Step 530, Loss: 0.24657775461673737\n",
      "Step 540, Loss: 0.24667924642562866\n",
      "Step 550, Loss: 0.2470427006483078\n",
      "Step 560, Loss: 0.24741213023662567\n",
      "Step 570, Loss: 0.2480732500553131\n",
      "Step 580, Loss: 0.24812963604927063\n",
      "Step 590, Loss: 0.24897807836532593\n",
      "Step 600, Loss: 0.24880966544151306\n",
      "Step 610, Loss: 0.2491879165172577\n",
      "Step 620, Loss: 0.25044137239456177\n",
      "Step 630, Loss: 0.25099843740463257\n",
      "Step 640, Loss: 0.25150594115257263\n",
      "Step 650, Loss: 0.2514025568962097\n",
      "Step 660, Loss: 0.25132089853286743\n",
      "Step 670, Loss: 0.25125232338905334\n",
      "Step 680, Loss: 0.251132071018219\n",
      "Step 690, Loss: 0.25120246410369873\n",
      "Step 700, Loss: 0.2511029839515686\n",
      "Step 710, Loss: 0.2509510815143585\n",
      "Step 720, Loss: 0.2508133351802826\n",
      "Step 730, Loss: 0.25067338347435\n",
      "Step 740, Loss: 0.25073614716529846\n",
      "Step 750, Loss: 0.2507324814796448\n",
      "Step 760, Loss: 0.24997001886367798\n",
      "Step 770, Loss: 0.24954231083393097\n",
      "Step 780, Loss: 0.24895277619361877\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-3\n",
      "\n",
      "ðŸš€ Epoch 4/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.0485030934214592\n",
      "Step 10, Loss: 0.04269889369606972\n",
      "Step 20, Loss: 0.04394129663705826\n",
      "Step 30, Loss: 0.04512951523065567\n",
      "Step 40, Loss: 0.04508932679891586\n",
      "Step 50, Loss: 0.043805986642837524\n",
      "Step 60, Loss: 0.043718595057725906\n",
      "Step 70, Loss: 0.04322204366326332\n",
      "Step 80, Loss: 0.042818743735551834\n",
      "Step 90, Loss: 0.042904872447252274\n",
      "Step 100, Loss: 0.04291710630059242\n",
      "Step 110, Loss: 0.04261203855276108\n",
      "Step 120, Loss: 0.04233330488204956\n",
      "Step 130, Loss: 0.04391409456729889\n",
      "Step 140, Loss: 0.04937124252319336\n",
      "Step 150, Loss: 0.05526525527238846\n",
      "Step 160, Loss: 0.062034156173467636\n",
      "Step 170, Loss: 0.0707215964794159\n",
      "Step 180, Loss: 0.07977671921253204\n",
      "Step 190, Loss: 0.08631717413663864\n",
      "Step 200, Loss: 0.09249003231525421\n",
      "Step 210, Loss: 0.09704732894897461\n",
      "Step 220, Loss: 0.10160543769598007\n",
      "Step 230, Loss: 0.10583148151636124\n",
      "Step 240, Loss: 0.11212610453367233\n",
      "Step 250, Loss: 0.1176898181438446\n",
      "Step 260, Loss: 0.1214858740568161\n",
      "Step 270, Loss: 0.12452542781829834\n",
      "Step 280, Loss: 0.12737709283828735\n",
      "Step 290, Loss: 0.13121218979358673\n",
      "Step 300, Loss: 0.13792946934700012\n",
      "Step 310, Loss: 0.14693360030651093\n",
      "Step 320, Loss: 0.1537182331085205\n",
      "Step 330, Loss: 0.16303566098213196\n",
      "Step 340, Loss: 0.17142224311828613\n",
      "Step 350, Loss: 0.17785383760929108\n",
      "Step 360, Loss: 0.18631164729595184\n",
      "Step 370, Loss: 0.1943713128566742\n",
      "Step 380, Loss: 0.20178095996379852\n",
      "Step 390, Loss: 0.20711638033390045\n",
      "Step 400, Loss: 0.21284455060958862\n",
      "Step 410, Loss: 0.21853387355804443\n",
      "Step 420, Loss: 0.22358635067939758\n",
      "Step 430, Loss: 0.2291988879442215\n",
      "Step 440, Loss: 0.2351834923028946\n",
      "Step 450, Loss: 0.23858065903186798\n",
      "Step 460, Loss: 0.2415594756603241\n",
      "Step 470, Loss: 0.2425304651260376\n",
      "Step 480, Loss: 0.24373376369476318\n",
      "Step 490, Loss: 0.24561920762062073\n",
      "Step 500, Loss: 0.24710269272327423\n",
      "Step 510, Loss: 0.24740774929523468\n",
      "Step 520, Loss: 0.24733532965183258\n",
      "Step 530, Loss: 0.2466951608657837\n",
      "Step 540, Loss: 0.2469193935394287\n",
      "Step 550, Loss: 0.24705441296100616\n",
      "Step 560, Loss: 0.24765492975711823\n",
      "Step 570, Loss: 0.24795344471931458\n",
      "Step 580, Loss: 0.24843347072601318\n",
      "Step 590, Loss: 0.24860920011997223\n",
      "Step 600, Loss: 0.2491782307624817\n",
      "Step 610, Loss: 0.2493916004896164\n",
      "Step 620, Loss: 0.2505268156528473\n",
      "Step 630, Loss: 0.25121447443962097\n",
      "Step 640, Loss: 0.2511017620563507\n",
      "Step 650, Loss: 0.25097015500068665\n",
      "Step 660, Loss: 0.2508251667022705\n",
      "Step 670, Loss: 0.251171737909317\n",
      "Step 680, Loss: 0.25120386481285095\n",
      "Step 690, Loss: 0.25073784589767456\n",
      "Step 700, Loss: 0.2510541081428528\n",
      "Step 710, Loss: 0.251206636428833\n",
      "Step 720, Loss: 0.25111985206604004\n",
      "Step 730, Loss: 0.2508138418197632\n",
      "Step 740, Loss: 0.2511367201805115\n",
      "Step 750, Loss: 0.2507917582988739\n",
      "Step 760, Loss: 0.24995428323745728\n",
      "Step 770, Loss: 0.24951189756393433\n",
      "Step 780, Loss: 0.2488173544406891\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-4\n",
      "\n",
      "ðŸš€ Epoch 5/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.05526987090706825\n",
      "Step 10, Loss: 0.04340675473213196\n",
      "Step 20, Loss: 0.04292931407690048\n",
      "Step 30, Loss: 0.0442662350833416\n",
      "Step 40, Loss: 0.04400445893406868\n",
      "Step 50, Loss: 0.04370665177702904\n",
      "Step 60, Loss: 0.04372503608465195\n",
      "Step 70, Loss: 0.04294643923640251\n",
      "Step 80, Loss: 0.0427071675658226\n",
      "Step 90, Loss: 0.04320143163204193\n",
      "Step 100, Loss: 0.04299730807542801\n",
      "Step 110, Loss: 0.04271393269300461\n",
      "Step 120, Loss: 0.04224555566906929\n",
      "Step 130, Loss: 0.04387656971812248\n",
      "Step 140, Loss: 0.04910628870129585\n",
      "Step 150, Loss: 0.055074118077754974\n",
      "Step 160, Loss: 0.06193695217370987\n",
      "Step 170, Loss: 0.06988685578107834\n",
      "Step 180, Loss: 0.07843691110610962\n",
      "Step 190, Loss: 0.0857761949300766\n",
      "Step 200, Loss: 0.09127957373857498\n",
      "Step 210, Loss: 0.09683151543140411\n",
      "Step 220, Loss: 0.10248690843582153\n",
      "Step 230, Loss: 0.10589766502380371\n",
      "Step 240, Loss: 0.11135318875312805\n",
      "Step 250, Loss: 0.11611050367355347\n",
      "Step 260, Loss: 0.12087959796190262\n",
      "Step 270, Loss: 0.12300809472799301\n",
      "Step 280, Loss: 0.12687155604362488\n",
      "Step 290, Loss: 0.1304650902748108\n",
      "Step 300, Loss: 0.13751555979251862\n",
      "Step 310, Loss: 0.14543768763542175\n",
      "Step 320, Loss: 0.15273058414459229\n",
      "Step 330, Loss: 0.16131752729415894\n",
      "Step 340, Loss: 0.16944563388824463\n",
      "Step 350, Loss: 0.17873205244541168\n",
      "Step 360, Loss: 0.1869092881679535\n",
      "Step 370, Loss: 0.19454273581504822\n",
      "Step 380, Loss: 0.2026079297065735\n",
      "Step 390, Loss: 0.2079208791255951\n",
      "Step 400, Loss: 0.2130550593137741\n",
      "Step 410, Loss: 0.2174759805202484\n",
      "Step 420, Loss: 0.22353950142860413\n",
      "Step 430, Loss: 0.2293972373008728\n",
      "Step 440, Loss: 0.23506611585617065\n",
      "Step 450, Loss: 0.23869413137435913\n",
      "Step 460, Loss: 0.24229294061660767\n",
      "Step 470, Loss: 0.24348987638950348\n",
      "Step 480, Loss: 0.24410884082317352\n",
      "Step 490, Loss: 0.245498925447464\n",
      "Step 500, Loss: 0.2463667243719101\n",
      "Step 510, Loss: 0.24607208371162415\n",
      "Step 520, Loss: 0.2456548660993576\n",
      "Step 530, Loss: 0.24521443247795105\n",
      "Step 540, Loss: 0.24574333429336548\n",
      "Step 550, Loss: 0.24662044644355774\n",
      "Step 560, Loss: 0.24792322516441345\n",
      "Step 570, Loss: 0.2485988438129425\n",
      "Step 580, Loss: 0.24892190098762512\n",
      "Step 590, Loss: 0.24897357821464539\n",
      "Step 600, Loss: 0.24877198040485382\n",
      "Step 610, Loss: 0.24906285107135773\n",
      "Step 620, Loss: 0.25031599402427673\n",
      "Step 630, Loss: 0.2504715323448181\n",
      "Step 640, Loss: 0.2502204179763794\n",
      "Step 650, Loss: 0.25083598494529724\n",
      "Step 660, Loss: 0.2507140040397644\n",
      "Step 670, Loss: 0.251145601272583\n",
      "Step 680, Loss: 0.251094788312912\n",
      "Step 690, Loss: 0.25050368905067444\n",
      "Step 700, Loss: 0.2508118450641632\n",
      "Step 710, Loss: 0.25041085481643677\n",
      "Step 720, Loss: 0.2505958378314972\n",
      "Step 730, Loss: 0.25070127844810486\n",
      "Step 740, Loss: 0.2504930794239044\n",
      "Step 750, Loss: 0.25028273463249207\n",
      "Step 760, Loss: 0.24963583052158356\n",
      "Step 770, Loss: 0.24908973276615143\n",
      "Step 780, Loss: 0.2487095445394516\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-5\n",
      "\n",
      "ðŸš€ Epoch 6/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.03597378358244896\n",
      "Step 10, Loss: 0.04078632965683937\n",
      "Step 20, Loss: 0.04305954650044441\n",
      "Step 30, Loss: 0.04505136236548424\n",
      "Step 40, Loss: 0.043877363204956055\n",
      "Step 50, Loss: 0.04344046488404274\n",
      "Step 60, Loss: 0.043211858719587326\n",
      "Step 70, Loss: 0.042581696063280106\n",
      "Step 80, Loss: 0.04228103160858154\n",
      "Step 90, Loss: 0.042654525488615036\n",
      "Step 100, Loss: 0.04272057116031647\n",
      "Step 110, Loss: 0.04256860539317131\n",
      "Step 120, Loss: 0.042366158217191696\n",
      "Step 130, Loss: 0.04521402716636658\n",
      "Step 140, Loss: 0.050021883100271225\n",
      "Step 150, Loss: 0.05690932273864746\n",
      "Step 160, Loss: 0.06305850297212601\n",
      "Step 170, Loss: 0.07054458558559418\n",
      "Step 180, Loss: 0.07925321161746979\n",
      "Step 190, Loss: 0.08609402179718018\n",
      "Step 200, Loss: 0.0910865068435669\n",
      "Step 210, Loss: 0.09615518152713776\n",
      "Step 220, Loss: 0.10082517564296722\n",
      "Step 230, Loss: 0.10517293959856033\n",
      "Step 240, Loss: 0.11084343492984772\n",
      "Step 250, Loss: 0.11590512096881866\n",
      "Step 260, Loss: 0.12051749229431152\n",
      "Step 270, Loss: 0.12360312789678574\n",
      "Step 280, Loss: 0.12646588683128357\n",
      "Step 290, Loss: 0.13010308146476746\n",
      "Step 300, Loss: 0.1359737664461136\n",
      "Step 310, Loss: 0.14344829320907593\n",
      "Step 320, Loss: 0.15278318524360657\n",
      "Step 330, Loss: 0.1607319861650467\n",
      "Step 340, Loss: 0.17004330456256866\n",
      "Step 350, Loss: 0.17790287733078003\n",
      "Step 360, Loss: 0.1859980821609497\n",
      "Step 370, Loss: 0.19455470144748688\n",
      "Step 380, Loss: 0.2030293494462967\n",
      "Step 390, Loss: 0.20888172090053558\n",
      "Step 400, Loss: 0.2122633457183838\n",
      "Step 410, Loss: 0.21876898407936096\n",
      "Step 420, Loss: 0.224358469247818\n",
      "Step 430, Loss: 0.22958992421627045\n",
      "Step 440, Loss: 0.2344108670949936\n",
      "Step 450, Loss: 0.2383638471364975\n",
      "Step 460, Loss: 0.24145343899726868\n",
      "Step 470, Loss: 0.24248428642749786\n",
      "Step 480, Loss: 0.24411751329898834\n",
      "Step 490, Loss: 0.24478191137313843\n",
      "Step 500, Loss: 0.24566636979579926\n",
      "Step 510, Loss: 0.24683308601379395\n",
      "Step 520, Loss: 0.24606022238731384\n",
      "Step 530, Loss: 0.24558937549591064\n",
      "Step 540, Loss: 0.24648576974868774\n",
      "Step 550, Loss: 0.24651841819286346\n",
      "Step 560, Loss: 0.24686963856220245\n",
      "Step 570, Loss: 0.24752117693424225\n",
      "Step 580, Loss: 0.2481376677751541\n",
      "Step 590, Loss: 0.24854744970798492\n",
      "Step 600, Loss: 0.2492663413286209\n",
      "Step 610, Loss: 0.25002023577690125\n",
      "Step 620, Loss: 0.25071030855178833\n",
      "Step 630, Loss: 0.25080662965774536\n",
      "Step 640, Loss: 0.2508780062198639\n",
      "Step 650, Loss: 0.250613808631897\n",
      "Step 660, Loss: 0.2504868805408478\n",
      "Step 670, Loss: 0.25059548020362854\n",
      "Step 680, Loss: 0.2506929039955139\n",
      "Step 690, Loss: 0.2507789731025696\n",
      "Step 700, Loss: 0.2507900893688202\n",
      "Step 710, Loss: 0.2506910562515259\n",
      "Step 720, Loss: 0.2505335807800293\n",
      "Step 730, Loss: 0.2507881224155426\n",
      "Step 740, Loss: 0.2507588863372803\n",
      "Step 750, Loss: 0.2501583695411682\n",
      "Step 760, Loss: 0.2499026507139206\n",
      "Step 770, Loss: 0.24930275976657867\n",
      "Step 780, Loss: 0.2487732172012329\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-6\n",
      "\n",
      "ðŸš€ Epoch 7/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.050954669713974\n",
      "Step 10, Loss: 0.044699881225824356\n",
      "Step 20, Loss: 0.044430579990148544\n",
      "Step 30, Loss: 0.045591648668050766\n",
      "Step 40, Loss: 0.04449884220957756\n",
      "Step 50, Loss: 0.043702736496925354\n",
      "Step 60, Loss: 0.04368617758154869\n",
      "Step 70, Loss: 0.04322806000709534\n",
      "Step 80, Loss: 0.04310325160622597\n",
      "Step 90, Loss: 0.04318270459771156\n",
      "Step 100, Loss: 0.04316521808505058\n",
      "Step 110, Loss: 0.043276891112327576\n",
      "Step 120, Loss: 0.0428156703710556\n",
      "Step 130, Loss: 0.044922806322574615\n",
      "Step 140, Loss: 0.048927731812000275\n",
      "Step 150, Loss: 0.05580104514956474\n",
      "Step 160, Loss: 0.062097541987895966\n",
      "Step 170, Loss: 0.06982024759054184\n",
      "Step 180, Loss: 0.07964807003736496\n",
      "Step 190, Loss: 0.08521774411201477\n",
      "Step 200, Loss: 0.09218993037939072\n",
      "Step 210, Loss: 0.09730155766010284\n",
      "Step 220, Loss: 0.1024600937962532\n",
      "Step 230, Loss: 0.10631897300481796\n",
      "Step 240, Loss: 0.11060143262147903\n",
      "Step 250, Loss: 0.11635811626911163\n",
      "Step 260, Loss: 0.12133156508207321\n",
      "Step 270, Loss: 0.1238657534122467\n",
      "Step 280, Loss: 0.12790796160697937\n",
      "Step 290, Loss: 0.13186128437519073\n",
      "Step 300, Loss: 0.1383977234363556\n",
      "Step 310, Loss: 0.14561045169830322\n",
      "Step 320, Loss: 0.1536889523267746\n",
      "Step 330, Loss: 0.16323795914649963\n",
      "Step 340, Loss: 0.1704501211643219\n",
      "Step 350, Loss: 0.18104679882526398\n",
      "Step 360, Loss: 0.1881747841835022\n",
      "Step 370, Loss: 0.1962745189666748\n",
      "Step 380, Loss: 0.20372554659843445\n",
      "Step 390, Loss: 0.2103036791086197\n",
      "Step 400, Loss: 0.21546773612499237\n",
      "Step 410, Loss: 0.22222423553466797\n",
      "Step 420, Loss: 0.22843170166015625\n",
      "Step 430, Loss: 0.23375053703784943\n",
      "Step 440, Loss: 0.23813949525356293\n",
      "Step 450, Loss: 0.24083539843559265\n",
      "Step 460, Loss: 0.24472971260547638\n",
      "Step 470, Loss: 0.24682386219501495\n",
      "Step 480, Loss: 0.24721041321754456\n",
      "Step 490, Loss: 0.24766933917999268\n",
      "Step 500, Loss: 0.24858857691287994\n",
      "Step 510, Loss: 0.24866916239261627\n",
      "Step 520, Loss: 0.2484523057937622\n",
      "Step 530, Loss: 0.24749934673309326\n",
      "Step 540, Loss: 0.24775885045528412\n",
      "Step 550, Loss: 0.24872887134552002\n",
      "Step 560, Loss: 0.24934861063957214\n",
      "Step 570, Loss: 0.24967575073242188\n",
      "Step 580, Loss: 0.2506162226200104\n",
      "Step 590, Loss: 0.2515580356121063\n",
      "Step 600, Loss: 0.25137606263160706\n",
      "Step 610, Loss: 0.2515828013420105\n",
      "Step 620, Loss: 0.25198256969451904\n",
      "Step 630, Loss: 0.25248315930366516\n",
      "Step 640, Loss: 0.25217291712760925\n",
      "Step 650, Loss: 0.2522224485874176\n",
      "Step 660, Loss: 0.2522643804550171\n",
      "Step 670, Loss: 0.252439945936203\n",
      "Step 680, Loss: 0.25221678614616394\n",
      "Step 690, Loss: 0.25179871916770935\n",
      "Step 700, Loss: 0.25207746028900146\n",
      "Step 710, Loss: 0.25229349732398987\n",
      "Step 720, Loss: 0.25269830226898193\n",
      "Step 730, Loss: 0.25271373987197876\n",
      "Step 740, Loss: 0.2525646686553955\n",
      "Step 750, Loss: 0.2519259750843048\n",
      "Step 760, Loss: 0.2513125240802765\n",
      "Step 770, Loss: 0.2506985664367676\n",
      "Step 780, Loss: 0.25012412667274475\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-7\n",
      "\n",
      "ðŸš€ Epoch 8/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.05198052525520325\n",
      "Step 10, Loss: 0.04625046253204346\n",
      "Step 20, Loss: 0.046433646231889725\n",
      "Step 30, Loss: 0.045653726905584335\n",
      "Step 40, Loss: 0.044779952615499496\n",
      "Step 50, Loss: 0.044416241347789764\n",
      "Step 60, Loss: 0.043957844376564026\n",
      "Step 70, Loss: 0.043736472725868225\n",
      "Step 80, Loss: 0.04333702102303505\n",
      "Step 90, Loss: 0.04356937110424042\n",
      "Step 100, Loss: 0.043127384036779404\n",
      "Step 110, Loss: 0.0426548570394516\n",
      "Step 120, Loss: 0.04252125695347786\n",
      "Step 130, Loss: 0.044841546565294266\n",
      "Step 140, Loss: 0.04980511590838432\n",
      "Step 150, Loss: 0.05548470839858055\n",
      "Step 160, Loss: 0.0629844218492508\n",
      "Step 170, Loss: 0.0703326165676117\n",
      "Step 180, Loss: 0.078749880194664\n",
      "Step 190, Loss: 0.08495087176561356\n",
      "Step 200, Loss: 0.09129814803600311\n",
      "Step 210, Loss: 0.09715045243501663\n",
      "Step 220, Loss: 0.1049550324678421\n",
      "Step 230, Loss: 0.10791341960430145\n",
      "Step 240, Loss: 0.11302459239959717\n",
      "Step 250, Loss: 0.11718516051769257\n",
      "Step 260, Loss: 0.12104539573192596\n",
      "Step 270, Loss: 0.12419598549604416\n",
      "Step 280, Loss: 0.1272045075893402\n",
      "Step 290, Loss: 0.1305026412010193\n",
      "Step 300, Loss: 0.1492118090391159\n",
      "Step 310, Loss: 0.20100359618663788\n",
      "Step 320, Loss: 0.20827464759349823\n",
      "Step 330, Loss: 0.2146250307559967\n",
      "Step 340, Loss: 0.22044438123703003\n",
      "Step 350, Loss: 0.22813433408737183\n",
      "Step 360, Loss: 0.23612794280052185\n",
      "Step 370, Loss: 0.24332204461097717\n",
      "Step 380, Loss: 0.2510131001472473\n",
      "Step 390, Loss: 0.2569160461425781\n",
      "Step 400, Loss: 0.2592805325984955\n",
      "Step 410, Loss: 0.2649356722831726\n",
      "Step 420, Loss: 0.26911208033561707\n",
      "Step 430, Loss: 0.27314671874046326\n",
      "Step 440, Loss: 0.27684271335601807\n",
      "Step 450, Loss: 0.27878737449645996\n",
      "Step 460, Loss: 0.28056204319000244\n",
      "Step 470, Loss: 0.2820911109447479\n",
      "Step 480, Loss: 0.2830789089202881\n",
      "Step 490, Loss: 0.28320255875587463\n",
      "Step 500, Loss: 0.2828354239463806\n",
      "Step 510, Loss: 0.28297707438468933\n",
      "Step 520, Loss: 0.28208908438682556\n",
      "Step 530, Loss: 0.28093859553337097\n",
      "Step 540, Loss: 0.2798766493797302\n",
      "Step 550, Loss: 0.2798362076282501\n",
      "Step 560, Loss: 0.2799544036388397\n",
      "Step 570, Loss: 0.2799762487411499\n",
      "Step 580, Loss: 0.2798622250556946\n",
      "Step 590, Loss: 0.2795235514640808\n",
      "Step 600, Loss: 0.2793687880039215\n",
      "Step 610, Loss: 0.279200941324234\n",
      "Step 620, Loss: 0.279664546251297\n",
      "Step 630, Loss: 0.27912527322769165\n",
      "Step 640, Loss: 0.2785005569458008\n",
      "Step 650, Loss: 0.27804240584373474\n",
      "Step 660, Loss: 0.2777465581893921\n",
      "Step 670, Loss: 0.2775441110134125\n",
      "Step 680, Loss: 0.2775585353374481\n",
      "Step 690, Loss: 0.27673855423927307\n",
      "Step 700, Loss: 0.27651625871658325\n",
      "Step 710, Loss: 0.2760826349258423\n",
      "Step 720, Loss: 0.2757059931755066\n",
      "Step 730, Loss: 0.27549490332603455\n",
      "Step 740, Loss: 0.2749728262424469\n",
      "Step 750, Loss: 0.2745784819126129\n",
      "Step 760, Loss: 0.2735767066478729\n",
      "Step 770, Loss: 0.27267664670944214\n",
      "Step 780, Loss: 0.2718610167503357\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-8\n",
      "\n",
      "ðŸš€ Epoch 9/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.03706783428788185\n",
      "Step 10, Loss: 0.04308660328388214\n",
      "Step 20, Loss: 0.04363509267568588\n",
      "Step 30, Loss: 0.04451223462820053\n",
      "Step 40, Loss: 0.04390943422913551\n",
      "Step 50, Loss: 0.04372651129961014\n",
      "Step 60, Loss: 0.043145641684532166\n",
      "Step 70, Loss: 0.042388249188661575\n",
      "Step 80, Loss: 0.04232119396328926\n",
      "Step 90, Loss: 0.04282427579164505\n",
      "Step 100, Loss: 0.042990848422050476\n",
      "Step 110, Loss: 0.04271095246076584\n",
      "Step 120, Loss: 0.04242033511400223\n",
      "Step 130, Loss: 0.043702952563762665\n",
      "Step 140, Loss: 0.049430448561906815\n",
      "Step 150, Loss: 0.057111214846372604\n",
      "Step 160, Loss: 0.06329052150249481\n",
      "Step 170, Loss: 0.06996957212686539\n",
      "Step 180, Loss: 0.07813558727502823\n",
      "Step 190, Loss: 0.0851769745349884\n",
      "Step 200, Loss: 0.09097070246934891\n",
      "Step 210, Loss: 0.09648638218641281\n",
      "Step 220, Loss: 0.10222247987985611\n",
      "Step 230, Loss: 0.10618457198143005\n",
      "Step 240, Loss: 0.11080355197191238\n",
      "Step 250, Loss: 0.11655236780643463\n",
      "Step 260, Loss: 0.12077291309833527\n",
      "Step 270, Loss: 0.12344010919332504\n",
      "Step 280, Loss: 0.12634803354740143\n",
      "Step 290, Loss: 0.13102753460407257\n",
      "Step 300, Loss: 0.13605274260044098\n",
      "Step 310, Loss: 0.14612577855587006\n",
      "Step 320, Loss: 0.1541934311389923\n",
      "Step 330, Loss: 0.1629403829574585\n",
      "Step 340, Loss: 0.16973713040351868\n",
      "Step 350, Loss: 0.1776532232761383\n",
      "Step 360, Loss: 0.1864180862903595\n",
      "Step 370, Loss: 0.1940067857503891\n",
      "Step 380, Loss: 0.2020203173160553\n",
      "Step 390, Loss: 0.2094084918498993\n",
      "Step 400, Loss: 0.21530288457870483\n",
      "Step 410, Loss: 0.22033369541168213\n",
      "Step 420, Loss: 0.2255401462316513\n",
      "Step 430, Loss: 0.22912083566188812\n",
      "Step 440, Loss: 0.23476850986480713\n",
      "Step 450, Loss: 0.23951493203639984\n",
      "Step 460, Loss: 0.2420705109834671\n",
      "Step 470, Loss: 0.24309366941452026\n",
      "Step 480, Loss: 0.24379831552505493\n",
      "Step 490, Loss: 0.24579665064811707\n",
      "Step 500, Loss: 0.2470420002937317\n",
      "Step 510, Loss: 0.2476986050605774\n",
      "Step 520, Loss: 0.24692660570144653\n",
      "Step 530, Loss: 0.2469397634267807\n",
      "Step 540, Loss: 0.24690543115139008\n",
      "Step 550, Loss: 0.24776099622249603\n",
      "Step 560, Loss: 0.24866048991680145\n",
      "Step 570, Loss: 0.24894177913665771\n",
      "Step 580, Loss: 0.24927902221679688\n",
      "Step 590, Loss: 0.24946974217891693\n",
      "Step 600, Loss: 0.24941226840019226\n",
      "Step 610, Loss: 0.2494937926530838\n",
      "Step 620, Loss: 0.2503626048564911\n",
      "Step 630, Loss: 0.250770628452301\n",
      "Step 640, Loss: 0.25057247281074524\n",
      "Step 650, Loss: 0.25080621242523193\n",
      "Step 660, Loss: 0.25087159872055054\n",
      "Step 670, Loss: 0.251239538192749\n",
      "Step 680, Loss: 0.2512377202510834\n",
      "Step 690, Loss: 0.2508131265640259\n",
      "Step 700, Loss: 0.2512105703353882\n",
      "Step 710, Loss: 0.25122833251953125\n",
      "Step 720, Loss: 0.25143858790397644\n",
      "Step 730, Loss: 0.25153523683547974\n",
      "Step 740, Loss: 0.251018226146698\n",
      "Step 750, Loss: 0.2505930960178375\n",
      "Step 760, Loss: 0.250136137008667\n",
      "Step 770, Loss: 0.24958278238773346\n",
      "Step 780, Loss: 0.24901318550109863\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-9\n",
      "\n",
      "ðŸš€ Epoch 10/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04283347353339195\n",
      "Step 10, Loss: 0.04118765890598297\n",
      "Step 20, Loss: 0.04287012293934822\n",
      "Step 30, Loss: 0.043404169380664825\n",
      "Step 40, Loss: 0.04329124838113785\n",
      "Step 50, Loss: 0.04312822222709656\n",
      "Step 60, Loss: 0.042969960719347\n",
      "Step 70, Loss: 0.04243350401520729\n",
      "Step 80, Loss: 0.042445436120033264\n",
      "Step 90, Loss: 0.04312828183174133\n",
      "Step 100, Loss: 0.04330245405435562\n",
      "Step 110, Loss: 0.042800161987543106\n",
      "Step 120, Loss: 0.04254402965307236\n",
      "Step 130, Loss: 0.043610718101263046\n",
      "Step 140, Loss: 0.048420947045087814\n",
      "Step 150, Loss: 0.05614910274744034\n",
      "Step 160, Loss: 0.06311586499214172\n",
      "Step 170, Loss: 0.0706862360239029\n",
      "Step 180, Loss: 0.07851481437683105\n",
      "Step 190, Loss: 0.08627507835626602\n",
      "Step 200, Loss: 0.09176837652921677\n",
      "Step 210, Loss: 0.09621912240982056\n",
      "Step 220, Loss: 0.10123153030872345\n",
      "Step 230, Loss: 0.10428133606910706\n",
      "Step 240, Loss: 0.11064697802066803\n",
      "Step 250, Loss: 0.11574996262788773\n",
      "Step 260, Loss: 0.12057469040155411\n",
      "Step 270, Loss: 0.12373146414756775\n",
      "Step 280, Loss: 0.12609703838825226\n",
      "Step 290, Loss: 0.1306113451719284\n",
      "Step 300, Loss: 0.13803251087665558\n",
      "Step 310, Loss: 0.14617495238780975\n",
      "Step 320, Loss: 0.15366865694522858\n",
      "Step 330, Loss: 0.1610722839832306\n",
      "Step 340, Loss: 0.16780750453472137\n",
      "Step 350, Loss: 0.17524857819080353\n",
      "Step 360, Loss: 0.18560945987701416\n",
      "Step 370, Loss: 0.19568654894828796\n",
      "Step 380, Loss: 0.20375441014766693\n",
      "Step 390, Loss: 0.20889486372470856\n",
      "Step 400, Loss: 0.21518158912658691\n",
      "Step 410, Loss: 0.22005192935466766\n",
      "Step 420, Loss: 0.2264600247144699\n",
      "Step 430, Loss: 0.23050224781036377\n",
      "Step 440, Loss: 0.23557113111019135\n",
      "Step 450, Loss: 0.23819352686405182\n",
      "Step 460, Loss: 0.24023297429084778\n",
      "Step 470, Loss: 0.2423514425754547\n",
      "Step 480, Loss: 0.24236135184764862\n",
      "Step 490, Loss: 0.24416209757328033\n",
      "Step 500, Loss: 0.2451051026582718\n",
      "Step 510, Loss: 0.24605342745780945\n",
      "Step 520, Loss: 0.24566315114498138\n",
      "Step 530, Loss: 0.2451658993959427\n",
      "Step 540, Loss: 0.2454472929239273\n",
      "Step 550, Loss: 0.24594368040561676\n",
      "Step 560, Loss: 0.24708066880702972\n",
      "Step 570, Loss: 0.247813418507576\n",
      "Step 580, Loss: 0.24845317006111145\n",
      "Step 590, Loss: 0.24882937967777252\n",
      "Step 600, Loss: 0.2490626573562622\n",
      "Step 610, Loss: 0.24973124265670776\n",
      "Step 620, Loss: 0.25039011240005493\n",
      "Step 630, Loss: 0.25080549716949463\n",
      "Step 640, Loss: 0.2511853277683258\n",
      "Step 650, Loss: 0.2511206567287445\n",
      "Step 660, Loss: 0.2510014474391937\n",
      "Step 670, Loss: 0.25106126070022583\n",
      "Step 680, Loss: 0.25123462080955505\n",
      "Step 690, Loss: 0.2508462965488434\n",
      "Step 700, Loss: 0.2511615753173828\n",
      "Step 710, Loss: 0.25121554732322693\n",
      "Step 720, Loss: 0.2512615919113159\n",
      "Step 730, Loss: 0.2515256702899933\n",
      "Step 740, Loss: 0.2512596547603607\n",
      "Step 750, Loss: 0.25081852078437805\n",
      "Step 760, Loss: 0.2504647672176361\n",
      "Step 770, Loss: 0.24963030219078064\n",
      "Step 780, Loss: 0.24900363385677338\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-10\n",
      "\n",
      "ðŸš€ Epoch 11/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04319247230887413\n",
      "Step 10, Loss: 0.042937591671943665\n",
      "Step 20, Loss: 0.04180704429745674\n",
      "Step 30, Loss: 0.04368095099925995\n",
      "Step 40, Loss: 0.04379238560795784\n",
      "Step 50, Loss: 0.04357808083295822\n",
      "Step 60, Loss: 0.04332791641354561\n",
      "Step 70, Loss: 0.04287518933415413\n",
      "Step 80, Loss: 0.043040681630373\n",
      "Step 90, Loss: 0.04360873997211456\n",
      "Step 100, Loss: 0.04355647414922714\n",
      "Step 110, Loss: 0.043235279619693756\n",
      "Step 120, Loss: 0.04272084683179855\n",
      "Step 130, Loss: 0.0443718321621418\n",
      "Step 140, Loss: 0.04820850118994713\n",
      "Step 150, Loss: 0.05637197941541672\n",
      "Step 160, Loss: 0.06201733276247978\n",
      "Step 170, Loss: 0.06718184053897858\n",
      "Step 180, Loss: 0.074006088078022\n",
      "Step 190, Loss: 0.08107403665781021\n",
      "Step 200, Loss: 0.08932151645421982\n",
      "Step 210, Loss: 0.09602997452020645\n",
      "Step 220, Loss: 0.1020527258515358\n",
      "Step 230, Loss: 0.10669364780187607\n",
      "Step 240, Loss: 0.11150003224611282\n",
      "Step 250, Loss: 0.11744485795497894\n",
      "Step 260, Loss: 0.12048917263746262\n",
      "Step 270, Loss: 0.12493125349283218\n",
      "Step 280, Loss: 0.12705540657043457\n",
      "Step 290, Loss: 0.13146646320819855\n",
      "Step 300, Loss: 0.13843759894371033\n",
      "Step 310, Loss: 0.1461944431066513\n",
      "Step 320, Loss: 0.15456905961036682\n",
      "Step 330, Loss: 0.1630050092935562\n",
      "Step 340, Loss: 0.17042458057403564\n",
      "Step 350, Loss: 0.17784656584262848\n",
      "Step 360, Loss: 0.18620052933692932\n",
      "Step 370, Loss: 0.19548454880714417\n",
      "Step 380, Loss: 0.20301614701747894\n",
      "Step 390, Loss: 0.20939211547374725\n",
      "Step 400, Loss: 0.21519127488136292\n",
      "Step 410, Loss: 0.22006580233573914\n",
      "Step 420, Loss: 0.2259524166584015\n",
      "Step 430, Loss: 0.2317933738231659\n",
      "Step 440, Loss: 0.235253244638443\n",
      "Step 450, Loss: 0.23812954127788544\n",
      "Step 460, Loss: 0.24093329906463623\n",
      "Step 470, Loss: 0.2426551729440689\n",
      "Step 480, Loss: 0.24352778494358063\n",
      "Step 490, Loss: 0.24537211656570435\n",
      "Step 500, Loss: 0.24622400104999542\n",
      "Step 510, Loss: 0.24635961651802063\n",
      "Step 520, Loss: 0.24569417536258698\n",
      "Step 530, Loss: 0.2455398142337799\n",
      "Step 540, Loss: 0.24553902447223663\n",
      "Step 550, Loss: 0.2465801239013672\n",
      "Step 560, Loss: 0.24754007160663605\n",
      "Step 570, Loss: 0.24810734391212463\n",
      "Step 580, Loss: 0.2486949861049652\n",
      "Step 590, Loss: 0.24933819472789764\n",
      "Step 600, Loss: 0.24966202676296234\n",
      "Step 610, Loss: 0.2494591772556305\n",
      "Step 620, Loss: 0.2500486373901367\n",
      "Step 630, Loss: 0.250603049993515\n",
      "Step 640, Loss: 0.25122785568237305\n",
      "Step 650, Loss: 0.2512611448764801\n",
      "Step 660, Loss: 0.25143811106681824\n",
      "Step 670, Loss: 0.25117194652557373\n",
      "Step 680, Loss: 0.2512725293636322\n",
      "Step 690, Loss: 0.250953733921051\n",
      "Step 700, Loss: 0.25147300958633423\n",
      "Step 710, Loss: 0.25151076912879944\n",
      "Step 720, Loss: 0.25143852829933167\n",
      "Step 730, Loss: 0.2517170310020447\n",
      "Step 740, Loss: 0.2515644431114197\n",
      "Step 750, Loss: 0.25102436542510986\n",
      "Step 760, Loss: 0.25027453899383545\n",
      "Step 770, Loss: 0.2497980147600174\n",
      "Step 780, Loss: 0.24899329245090485\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-11\n",
      "\n",
      "ðŸš€ Epoch 12/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04854603484272957\n",
      "Step 10, Loss: 0.04286884516477585\n",
      "Step 20, Loss: 0.044218990951776505\n",
      "Step 30, Loss: 0.045281339436769485\n",
      "Step 40, Loss: 0.044952161610126495\n",
      "Step 50, Loss: 0.0437079519033432\n",
      "Step 60, Loss: 0.043809447437524796\n",
      "Step 70, Loss: 0.043371908366680145\n",
      "Step 80, Loss: 0.04305916279554367\n",
      "Step 90, Loss: 0.043748434633016586\n",
      "Step 100, Loss: 0.043168969452381134\n",
      "Step 110, Loss: 0.04267984628677368\n",
      "Step 120, Loss: 0.042398832738399506\n",
      "Step 130, Loss: 0.04415168985724449\n",
      "Step 140, Loss: 0.051052991300821304\n",
      "Step 150, Loss: 0.05741867050528526\n",
      "Step 160, Loss: 0.063226617872715\n",
      "Step 170, Loss: 0.06885558366775513\n",
      "Step 180, Loss: 0.076962411403656\n",
      "Step 190, Loss: 0.08293195068836212\n",
      "Step 200, Loss: 0.08890073001384735\n",
      "Step 210, Loss: 0.09454448521137238\n",
      "Step 220, Loss: 0.10104305297136307\n",
      "Step 230, Loss: 0.1049850657582283\n",
      "Step 240, Loss: 0.11106385290622711\n",
      "Step 250, Loss: 0.11620474606752396\n",
      "Step 260, Loss: 0.12000913172960281\n",
      "Step 270, Loss: 0.12360680848360062\n",
      "Step 280, Loss: 0.12660855054855347\n",
      "Step 290, Loss: 0.1318158060312271\n",
      "Step 300, Loss: 0.1379980742931366\n",
      "Step 310, Loss: 0.14612258970737457\n",
      "Step 320, Loss: 0.15397998690605164\n",
      "Step 330, Loss: 0.16325148940086365\n",
      "Step 340, Loss: 0.17189443111419678\n",
      "Step 350, Loss: 0.17830264568328857\n",
      "Step 360, Loss: 0.18850433826446533\n",
      "Step 370, Loss: 0.19618543982505798\n",
      "Step 380, Loss: 0.20549628138542175\n",
      "Step 390, Loss: 0.21163417398929596\n",
      "Step 400, Loss: 0.21609732508659363\n",
      "Step 410, Loss: 0.22058899700641632\n",
      "Step 420, Loss: 0.22646412253379822\n",
      "Step 430, Loss: 0.2312891185283661\n",
      "Step 440, Loss: 0.23603768646717072\n",
      "Step 450, Loss: 0.23803947865962982\n",
      "Step 460, Loss: 0.2399979680776596\n",
      "Step 470, Loss: 0.2418549507856369\n",
      "Step 480, Loss: 0.24301815032958984\n",
      "Step 490, Loss: 0.24533958733081818\n",
      "Step 500, Loss: 0.24589598178863525\n",
      "Step 510, Loss: 0.24673549830913544\n",
      "Step 520, Loss: 0.24698716402053833\n",
      "Step 530, Loss: 0.24662481248378754\n",
      "Step 540, Loss: 0.2467578649520874\n",
      "Step 550, Loss: 0.2474982738494873\n",
      "Step 560, Loss: 0.24822138249874115\n",
      "Step 570, Loss: 0.2484103888273239\n",
      "Step 580, Loss: 0.2485208362340927\n",
      "Step 590, Loss: 0.24870194494724274\n",
      "Step 600, Loss: 0.24895374476909637\n",
      "Step 610, Loss: 0.24994495511054993\n",
      "Step 620, Loss: 0.250828355550766\n",
      "Step 630, Loss: 0.2515682578086853\n",
      "Step 640, Loss: 0.25104618072509766\n",
      "Step 650, Loss: 0.25133368372917175\n",
      "Step 660, Loss: 0.2512238025665283\n",
      "Step 670, Loss: 0.2510722577571869\n",
      "Step 680, Loss: 0.2510957717895508\n",
      "Step 690, Loss: 0.25075167417526245\n",
      "Step 700, Loss: 0.2505732476711273\n",
      "Step 710, Loss: 0.2507386803627014\n",
      "Step 720, Loss: 0.25075235962867737\n",
      "Step 730, Loss: 0.2506597340106964\n",
      "Step 740, Loss: 0.2504884600639343\n",
      "Step 750, Loss: 0.2501462399959564\n",
      "Step 760, Loss: 0.24983040988445282\n",
      "Step 770, Loss: 0.24951599538326263\n",
      "Step 780, Loss: 0.24894526600837708\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-12\n",
      "\n",
      "ðŸš€ Epoch 13/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.032272543758153915\n",
      "Step 10, Loss: 0.04161239042878151\n",
      "Step 20, Loss: 0.04248489439487457\n",
      "Step 30, Loss: 0.04488815367221832\n",
      "Step 40, Loss: 0.043953172862529755\n",
      "Step 50, Loss: 0.04387356713414192\n",
      "Step 60, Loss: 0.04316215217113495\n",
      "Step 70, Loss: 0.042970575392246246\n",
      "Step 80, Loss: 0.04266946390271187\n",
      "Step 90, Loss: 0.043161533772945404\n",
      "Step 100, Loss: 0.04287254810333252\n",
      "Step 110, Loss: 0.04277566447854042\n",
      "Step 120, Loss: 0.042635478079319\n",
      "Step 130, Loss: 0.044704634696245193\n",
      "Step 140, Loss: 0.05023057386279106\n",
      "Step 150, Loss: 0.05675940960645676\n",
      "Step 160, Loss: 0.06253720819950104\n",
      "Step 170, Loss: 0.06895918399095535\n",
      "Step 180, Loss: 0.07775469869375229\n",
      "Step 190, Loss: 0.0837651714682579\n",
      "Step 200, Loss: 0.09117182344198227\n",
      "Step 210, Loss: 0.09614052623510361\n",
      "Step 220, Loss: 0.10158047080039978\n",
      "Step 230, Loss: 0.10618460178375244\n",
      "Step 240, Loss: 0.11035578697919846\n",
      "Step 250, Loss: 0.1163998395204544\n",
      "Step 260, Loss: 0.12065289169549942\n",
      "Step 270, Loss: 0.12473650276660919\n",
      "Step 280, Loss: 0.12767638266086578\n",
      "Step 290, Loss: 0.13237634301185608\n",
      "Step 300, Loss: 0.13909170031547546\n",
      "Step 310, Loss: 0.14565294981002808\n",
      "Step 320, Loss: 0.15474288165569305\n",
      "Step 330, Loss: 0.16249825060367584\n",
      "Step 340, Loss: 0.17029766738414764\n",
      "Step 350, Loss: 0.17757494747638702\n",
      "Step 360, Loss: 0.1866806149482727\n",
      "Step 370, Loss: 0.1948053389787674\n",
      "Step 380, Loss: 0.20185241103172302\n",
      "Step 390, Loss: 0.20864708721637726\n",
      "Step 400, Loss: 0.21443726122379303\n",
      "Step 410, Loss: 0.22032293677330017\n",
      "Step 420, Loss: 0.22627946734428406\n",
      "Step 430, Loss: 0.23106947541236877\n",
      "Step 440, Loss: 0.23533450067043304\n",
      "Step 450, Loss: 0.2380620837211609\n",
      "Step 460, Loss: 0.2412051260471344\n",
      "Step 470, Loss: 0.24268755316734314\n",
      "Step 480, Loss: 0.24409306049346924\n",
      "Step 490, Loss: 0.24555762112140656\n",
      "Step 500, Loss: 0.2464095950126648\n",
      "Step 510, Loss: 0.2469957172870636\n",
      "Step 520, Loss: 0.24715255200862885\n",
      "Step 530, Loss: 0.2465624064207077\n",
      "Step 540, Loss: 0.24664509296417236\n",
      "Step 550, Loss: 0.24765914678573608\n",
      "Step 560, Loss: 0.24826152622699738\n",
      "Step 570, Loss: 0.24931368231773376\n",
      "Step 580, Loss: 0.24905024468898773\n",
      "Step 590, Loss: 0.2488652467727661\n",
      "Step 600, Loss: 0.24938055872917175\n",
      "Step 610, Loss: 0.2496122568845749\n",
      "Step 620, Loss: 0.25051620602607727\n",
      "Step 630, Loss: 0.251461923122406\n",
      "Step 640, Loss: 0.2512451410293579\n",
      "Step 650, Loss: 0.2515164613723755\n",
      "Step 660, Loss: 0.25151363015174866\n",
      "Step 670, Loss: 0.2514774799346924\n",
      "Step 680, Loss: 0.25138211250305176\n",
      "Step 690, Loss: 0.25092896819114685\n",
      "Step 700, Loss: 0.2510021924972534\n",
      "Step 710, Loss: 0.2508765459060669\n",
      "Step 720, Loss: 0.2510707974433899\n",
      "Step 730, Loss: 0.25117385387420654\n",
      "Step 740, Loss: 0.25123634934425354\n",
      "Step 750, Loss: 0.25093474984169006\n",
      "Step 760, Loss: 0.2502593696117401\n",
      "Step 770, Loss: 0.24948444962501526\n",
      "Step 780, Loss: 0.24892321228981018\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-13\n",
      "\n",
      "ðŸš€ Epoch 14/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04306575655937195\n",
      "Step 10, Loss: 0.04262576252222061\n",
      "Step 20, Loss: 0.04303736612200737\n",
      "Step 30, Loss: 0.04498129338026047\n",
      "Step 40, Loss: 0.04362018406391144\n",
      "Step 50, Loss: 0.042834728956222534\n",
      "Step 60, Loss: 0.04315144196152687\n",
      "Step 70, Loss: 0.04284421727061272\n",
      "Step 80, Loss: 0.04294130578637123\n",
      "Step 90, Loss: 0.043288085609674454\n",
      "Step 100, Loss: 0.043026477098464966\n",
      "Step 110, Loss: 0.04257308691740036\n",
      "Step 120, Loss: 0.04234893620014191\n",
      "Step 130, Loss: 0.04398656636476517\n",
      "Step 140, Loss: 0.04808572679758072\n",
      "Step 150, Loss: 0.05360785126686096\n",
      "Step 160, Loss: 0.06135808303952217\n",
      "Step 170, Loss: 0.06893527507781982\n",
      "Step 180, Loss: 0.07744423300027847\n",
      "Step 190, Loss: 0.0839376300573349\n",
      "Step 200, Loss: 0.09029728174209595\n",
      "Step 210, Loss: 0.09651794284582138\n",
      "Step 220, Loss: 0.10155683755874634\n",
      "Step 230, Loss: 0.10484025627374649\n",
      "Step 240, Loss: 0.11116338521242142\n",
      "Step 250, Loss: 0.11739061027765274\n",
      "Step 260, Loss: 0.12150119245052338\n",
      "Step 270, Loss: 0.12441454827785492\n",
      "Step 280, Loss: 0.12748506665229797\n",
      "Step 290, Loss: 0.130997896194458\n",
      "Step 300, Loss: 0.13762420415878296\n",
      "Step 310, Loss: 0.14597976207733154\n",
      "Step 320, Loss: 0.15389370918273926\n",
      "Step 330, Loss: 0.16283439099788666\n",
      "Step 340, Loss: 0.17029500007629395\n",
      "Step 350, Loss: 0.17811602354049683\n",
      "Step 360, Loss: 0.1869392693042755\n",
      "Step 370, Loss: 0.19487853348255157\n",
      "Step 380, Loss: 0.20144397020339966\n",
      "Step 390, Loss: 0.20836935937404633\n",
      "Step 400, Loss: 0.21350470185279846\n",
      "Step 410, Loss: 0.21903739869594574\n",
      "Step 420, Loss: 0.22507119178771973\n",
      "Step 430, Loss: 0.2294643670320511\n",
      "Step 440, Loss: 0.2352505326271057\n",
      "Step 450, Loss: 0.23973912000656128\n",
      "Step 460, Loss: 0.24197757244110107\n",
      "Step 470, Loss: 0.24419458210468292\n",
      "Step 480, Loss: 0.24508219957351685\n",
      "Step 490, Loss: 0.24596838653087616\n",
      "Step 500, Loss: 0.2462567538022995\n",
      "Step 510, Loss: 0.2466728687286377\n",
      "Step 520, Loss: 0.24625559151172638\n",
      "Step 530, Loss: 0.24622854590415955\n",
      "Step 540, Loss: 0.24570444226264954\n",
      "Step 550, Loss: 0.2467419058084488\n",
      "Step 560, Loss: 0.24723710119724274\n",
      "Step 570, Loss: 0.24815082550048828\n",
      "Step 580, Loss: 0.248513326048851\n",
      "Step 590, Loss: 0.24904628098011017\n",
      "Step 600, Loss: 0.24925361573696136\n",
      "Step 610, Loss: 0.24989548325538635\n",
      "Step 620, Loss: 0.25015056133270264\n",
      "Step 630, Loss: 0.2509961426258087\n",
      "Step 640, Loss: 0.25084224343299866\n",
      "Step 650, Loss: 0.2511756122112274\n",
      "Step 660, Loss: 0.2513684630393982\n",
      "Step 670, Loss: 0.25123322010040283\n",
      "Step 680, Loss: 0.2512933313846588\n",
      "Step 690, Loss: 0.25106164813041687\n",
      "Step 700, Loss: 0.25121572613716125\n",
      "Step 710, Loss: 0.25112035870552063\n",
      "Step 720, Loss: 0.25114861130714417\n",
      "Step 730, Loss: 0.2512308359146118\n",
      "Step 740, Loss: 0.25102338194847107\n",
      "Step 750, Loss: 0.25092050433158875\n",
      "Step 760, Loss: 0.25030967593193054\n",
      "Step 770, Loss: 0.24966810643672943\n",
      "Step 780, Loss: 0.24892818927764893\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-14\n",
      "\n",
      "ðŸš€ Epoch 15/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.0310081634670496\n",
      "Step 10, Loss: 0.04210517182946205\n",
      "Step 20, Loss: 0.04417577013373375\n",
      "Step 30, Loss: 0.04606405645608902\n",
      "Step 40, Loss: 0.044089678674936295\n",
      "Step 50, Loss: 0.04327212646603584\n",
      "Step 60, Loss: 0.04308079928159714\n",
      "Step 70, Loss: 0.04242667183279991\n",
      "Step 80, Loss: 0.04256067052483559\n",
      "Step 90, Loss: 0.04279343783855438\n",
      "Step 100, Loss: 0.043001338839530945\n",
      "Step 110, Loss: 0.04288283362984657\n",
      "Step 120, Loss: 0.0425899401307106\n",
      "Step 130, Loss: 0.04405530169606209\n",
      "Step 140, Loss: 0.049542780965566635\n",
      "Step 150, Loss: 0.05679463967680931\n",
      "Step 160, Loss: 0.06403812021017075\n",
      "Step 170, Loss: 0.07144230604171753\n",
      "Step 180, Loss: 0.07819802314043045\n",
      "Step 190, Loss: 0.08647029101848602\n",
      "Step 200, Loss: 0.09390320628881454\n",
      "Step 210, Loss: 0.09836868196725845\n",
      "Step 220, Loss: 0.10224016010761261\n",
      "Step 230, Loss: 0.10599739104509354\n",
      "Step 240, Loss: 0.11110519617795944\n",
      "Step 250, Loss: 0.11637338995933533\n",
      "Step 260, Loss: 0.12051457911729813\n",
      "Step 270, Loss: 0.12312272191047668\n",
      "Step 280, Loss: 0.1256430447101593\n",
      "Step 290, Loss: 0.13026313483715057\n",
      "Step 300, Loss: 0.13610826432704926\n",
      "Step 310, Loss: 0.14501380920410156\n",
      "Step 320, Loss: 0.15384885668754578\n",
      "Step 330, Loss: 0.1616727113723755\n",
      "Step 340, Loss: 0.17090535163879395\n",
      "Step 350, Loss: 0.17894011735916138\n",
      "Step 360, Loss: 0.18653504550457\n",
      "Step 370, Loss: 0.19624648988246918\n",
      "Step 380, Loss: 0.2027616947889328\n",
      "Step 390, Loss: 0.208314448595047\n",
      "Step 400, Loss: 0.21447144448757172\n",
      "Step 410, Loss: 0.21905049681663513\n",
      "Step 420, Loss: 0.22632372379302979\n",
      "Step 430, Loss: 0.23066581785678864\n",
      "Step 440, Loss: 0.2348736971616745\n",
      "Step 450, Loss: 0.23827491700649261\n",
      "Step 460, Loss: 0.2416677474975586\n",
      "Step 470, Loss: 0.24391819536685944\n",
      "Step 480, Loss: 0.24515576660633087\n",
      "Step 490, Loss: 0.24647670984268188\n",
      "Step 500, Loss: 0.24692977964878082\n",
      "Step 510, Loss: 0.2470272183418274\n",
      "Step 520, Loss: 0.2467074692249298\n",
      "Step 530, Loss: 0.24644355475902557\n",
      "Step 540, Loss: 0.24628254771232605\n",
      "Step 550, Loss: 0.24665793776512146\n",
      "Step 560, Loss: 0.24731062352657318\n",
      "Step 570, Loss: 0.24831300973892212\n",
      "Step 580, Loss: 0.24839703738689423\n",
      "Step 590, Loss: 0.24883227050304413\n",
      "Step 600, Loss: 0.2490774393081665\n",
      "Step 610, Loss: 0.2496340125799179\n",
      "Step 620, Loss: 0.2500850558280945\n",
      "Step 630, Loss: 0.25051742792129517\n",
      "Step 640, Loss: 0.2505647540092468\n",
      "Step 650, Loss: 0.25070685148239136\n",
      "Step 660, Loss: 0.25079694390296936\n",
      "Step 670, Loss: 0.2507440745830536\n",
      "Step 680, Loss: 0.2508505880832672\n",
      "Step 690, Loss: 0.2508511543273926\n",
      "Step 700, Loss: 0.2508139908313751\n",
      "Step 710, Loss: 0.25109776854515076\n",
      "Step 720, Loss: 0.25093787908554077\n",
      "Step 730, Loss: 0.2510298490524292\n",
      "Step 740, Loss: 0.25076431035995483\n",
      "Step 750, Loss: 0.2505651116371155\n",
      "Step 760, Loss: 0.2500060200691223\n",
      "Step 770, Loss: 0.24947407841682434\n",
      "Step 780, Loss: 0.24899142980575562\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-15\n",
      "\n",
      "ðŸš€ Epoch 16/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04040831699967384\n",
      "Step 10, Loss: 0.04127989709377289\n",
      "Step 20, Loss: 0.04228740930557251\n",
      "Step 30, Loss: 0.044045913964509964\n",
      "Step 40, Loss: 0.043524742126464844\n",
      "Step 50, Loss: 0.04322386160492897\n",
      "Step 60, Loss: 0.042996879667043686\n",
      "Step 70, Loss: 0.04236232489347458\n",
      "Step 80, Loss: 0.04250936582684517\n",
      "Step 90, Loss: 0.04309554770588875\n",
      "Step 100, Loss: 0.0430431067943573\n",
      "Step 110, Loss: 0.042758118361234665\n",
      "Step 120, Loss: 0.042521487921476364\n",
      "Step 130, Loss: 0.04469829797744751\n",
      "Step 140, Loss: 0.04953255131840706\n",
      "Step 150, Loss: 0.056926000863313675\n",
      "Step 160, Loss: 0.06174566224217415\n",
      "Step 170, Loss: 0.06803810596466064\n",
      "Step 180, Loss: 0.07721485197544098\n",
      "Step 190, Loss: 0.0846438854932785\n",
      "Step 200, Loss: 0.0899229347705841\n",
      "Step 210, Loss: 0.09529309719800949\n",
      "Step 220, Loss: 0.10199984163045883\n",
      "Step 230, Loss: 0.10639523714780807\n",
      "Step 240, Loss: 0.11072034388780594\n",
      "Step 250, Loss: 0.11677929759025574\n",
      "Step 260, Loss: 0.12106452882289886\n",
      "Step 270, Loss: 0.12403317540884018\n",
      "Step 280, Loss: 0.12691240012645721\n",
      "Step 290, Loss: 0.13090117275714874\n",
      "Step 300, Loss: 0.1383739411830902\n",
      "Step 310, Loss: 0.14513780176639557\n",
      "Step 320, Loss: 0.1517356038093567\n",
      "Step 330, Loss: 0.1609068661928177\n",
      "Step 340, Loss: 0.1681588739156723\n",
      "Step 350, Loss: 0.17640374600887299\n",
      "Step 360, Loss: 0.18568065762519836\n",
      "Step 370, Loss: 0.19574925303459167\n",
      "Step 380, Loss: 0.20388241112232208\n",
      "Step 390, Loss: 0.20914731919765472\n",
      "Step 400, Loss: 0.21506643295288086\n",
      "Step 410, Loss: 0.21981215476989746\n",
      "Step 420, Loss: 0.22608299553394318\n",
      "Step 430, Loss: 0.2307480275630951\n",
      "Step 440, Loss: 0.2346877008676529\n",
      "Step 450, Loss: 0.23819848895072937\n",
      "Step 460, Loss: 0.24080772697925568\n",
      "Step 470, Loss: 0.24207830429077148\n",
      "Step 480, Loss: 0.24384868144989014\n",
      "Step 490, Loss: 0.24486708641052246\n",
      "Step 500, Loss: 0.2455446422100067\n",
      "Step 510, Loss: 0.24707846343517303\n",
      "Step 520, Loss: 0.24689722061157227\n",
      "Step 530, Loss: 0.2465689778327942\n",
      "Step 540, Loss: 0.24714098870754242\n",
      "Step 550, Loss: 0.24723787605762482\n",
      "Step 560, Loss: 0.2480165958404541\n",
      "Step 570, Loss: 0.2483757585287094\n",
      "Step 580, Loss: 0.24821209907531738\n",
      "Step 590, Loss: 0.24868516623973846\n",
      "Step 600, Loss: 0.24908262491226196\n",
      "Step 610, Loss: 0.24986344575881958\n",
      "Step 620, Loss: 0.250852108001709\n",
      "Step 630, Loss: 0.25109487771987915\n",
      "Step 640, Loss: 0.25095096230506897\n",
      "Step 650, Loss: 0.25069737434387207\n",
      "Step 660, Loss: 0.25096040964126587\n",
      "Step 670, Loss: 0.2511655390262604\n",
      "Step 680, Loss: 0.251147985458374\n",
      "Step 690, Loss: 0.2514764666557312\n",
      "Step 700, Loss: 0.25112706422805786\n",
      "Step 710, Loss: 0.2510390877723694\n",
      "Step 720, Loss: 0.2510342597961426\n",
      "Step 730, Loss: 0.2511034905910492\n",
      "Step 740, Loss: 0.25118979811668396\n",
      "Step 750, Loss: 0.25068846344947815\n",
      "Step 760, Loss: 0.2500515878200531\n",
      "Step 770, Loss: 0.2495412677526474\n",
      "Step 780, Loss: 0.24901966750621796\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-16\n",
      "\n",
      "ðŸš€ Epoch 17/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04377160593867302\n",
      "Step 10, Loss: 0.041833434253931046\n",
      "Step 20, Loss: 0.04447510465979576\n",
      "Step 30, Loss: 0.046211156994104385\n",
      "Step 40, Loss: 0.044741109013557434\n",
      "Step 50, Loss: 0.04432240501046181\n",
      "Step 60, Loss: 0.044118039309978485\n",
      "Step 70, Loss: 0.04334576055407524\n",
      "Step 80, Loss: 0.04320688918232918\n",
      "Step 90, Loss: 0.04329349845647812\n",
      "Step 100, Loss: 0.04316568747162819\n",
      "Step 110, Loss: 0.04264010861515999\n",
      "Step 120, Loss: 0.042280398309230804\n",
      "Step 130, Loss: 0.04465865716338158\n",
      "Step 140, Loss: 0.04904185235500336\n",
      "Step 150, Loss: 0.054288189858198166\n",
      "Step 160, Loss: 0.060733404010534286\n",
      "Step 170, Loss: 0.06862681359052658\n",
      "Step 180, Loss: 0.07618158310651779\n",
      "Step 190, Loss: 0.08361422270536423\n",
      "Step 200, Loss: 0.0905107781291008\n",
      "Step 210, Loss: 0.09568458795547485\n",
      "Step 220, Loss: 0.10136298835277557\n",
      "Step 230, Loss: 0.10592066496610641\n",
      "Step 240, Loss: 0.11165553331375122\n",
      "Step 250, Loss: 0.11706400662660599\n",
      "Step 260, Loss: 0.1214609295129776\n",
      "Step 270, Loss: 0.12502408027648926\n",
      "Step 280, Loss: 0.12751029431819916\n",
      "Step 290, Loss: 0.12988102436065674\n",
      "Step 300, Loss: 0.13628965616226196\n",
      "Step 310, Loss: 0.14287473261356354\n",
      "Step 320, Loss: 0.15175917744636536\n",
      "Step 330, Loss: 0.15932981669902802\n",
      "Step 340, Loss: 0.1693134307861328\n",
      "Step 350, Loss: 0.17813383042812347\n",
      "Step 360, Loss: 0.18703864514827728\n",
      "Step 370, Loss: 0.19719728827476501\n",
      "Step 380, Loss: 0.20296648144721985\n",
      "Step 390, Loss: 0.21023504436016083\n",
      "Step 400, Loss: 0.21538473665714264\n",
      "Step 410, Loss: 0.22014831006526947\n",
      "Step 420, Loss: 0.22646506130695343\n",
      "Step 430, Loss: 0.23104526102542877\n",
      "Step 440, Loss: 0.235094353556633\n",
      "Step 450, Loss: 0.23903866112232208\n",
      "Step 460, Loss: 0.2420877367258072\n",
      "Step 470, Loss: 0.24367155134677887\n",
      "Step 480, Loss: 0.24465376138687134\n",
      "Step 490, Loss: 0.2459786981344223\n",
      "Step 500, Loss: 0.24721276760101318\n",
      "Step 510, Loss: 0.2473101168870926\n",
      "Step 520, Loss: 0.24709904193878174\n",
      "Step 530, Loss: 0.24637116491794586\n",
      "Step 540, Loss: 0.24641965329647064\n",
      "Step 550, Loss: 0.24720509350299835\n",
      "Step 560, Loss: 0.24745191633701324\n",
      "Step 570, Loss: 0.24799922108650208\n",
      "Step 580, Loss: 0.24912990629673004\n",
      "Step 590, Loss: 0.249737948179245\n",
      "Step 600, Loss: 0.24974367022514343\n",
      "Step 610, Loss: 0.2500922381877899\n",
      "Step 620, Loss: 0.25103095173835754\n",
      "Step 630, Loss: 0.25145286321640015\n",
      "Step 640, Loss: 0.2511572539806366\n",
      "Step 650, Loss: 0.25092411041259766\n",
      "Step 660, Loss: 0.25101447105407715\n",
      "Step 670, Loss: 0.25107303261756897\n",
      "Step 680, Loss: 0.2512621283531189\n",
      "Step 690, Loss: 0.25094735622406006\n",
      "Step 700, Loss: 0.25084298849105835\n",
      "Step 710, Loss: 0.25095227360725403\n",
      "Step 720, Loss: 0.2510770559310913\n",
      "Step 730, Loss: 0.25115054845809937\n",
      "Step 740, Loss: 0.25077784061431885\n",
      "Step 750, Loss: 0.25069764256477356\n",
      "Step 760, Loss: 0.25012093782424927\n",
      "Step 770, Loss: 0.24922335147857666\n",
      "Step 780, Loss: 0.2489524632692337\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-17\n",
      "\n",
      "ðŸš€ Epoch 18/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.04526445269584656\n",
      "Step 10, Loss: 0.044057078659534454\n",
      "Step 20, Loss: 0.043632883578538895\n",
      "Step 30, Loss: 0.04534663259983063\n",
      "Step 40, Loss: 0.04424852132797241\n",
      "Step 50, Loss: 0.043659817427396774\n",
      "Step 60, Loss: 0.04364743456244469\n",
      "Step 70, Loss: 0.0435650534927845\n",
      "Step 80, Loss: 0.0428849533200264\n",
      "Step 90, Loss: 0.04314962401986122\n",
      "Step 100, Loss: 0.04304947331547737\n",
      "Step 110, Loss: 0.0428757406771183\n",
      "Step 120, Loss: 0.042644523084163666\n",
      "Step 130, Loss: 0.04422009363770485\n",
      "Step 140, Loss: 0.04911148175597191\n",
      "Step 150, Loss: 0.05711225047707558\n",
      "Step 160, Loss: 0.06192709505558014\n",
      "Step 170, Loss: 0.06936521828174591\n",
      "Step 180, Loss: 0.07842098921537399\n",
      "Step 190, Loss: 0.08569033443927765\n",
      "Step 200, Loss: 0.08966811001300812\n",
      "Step 210, Loss: 0.09555350244045258\n",
      "Step 220, Loss: 0.10116659104824066\n",
      "Step 230, Loss: 0.10478708148002625\n",
      "Step 240, Loss: 0.10915912687778473\n",
      "Step 250, Loss: 0.11614180356264114\n",
      "Step 260, Loss: 0.12063371390104294\n",
      "Step 270, Loss: 0.12374719977378845\n",
      "Step 280, Loss: 0.1272323876619339\n",
      "Step 290, Loss: 0.1313554048538208\n",
      "Step 300, Loss: 0.13784970343112946\n",
      "Step 310, Loss: 0.14548775553703308\n",
      "Step 320, Loss: 0.15414246916770935\n",
      "Step 330, Loss: 0.16288545727729797\n",
      "Step 340, Loss: 0.17053301632404327\n",
      "Step 350, Loss: 0.1794145256280899\n",
      "Step 360, Loss: 0.18683457374572754\n",
      "Step 370, Loss: 0.19419293105602264\n",
      "Step 380, Loss: 0.20170338451862335\n",
      "Step 390, Loss: 0.20864337682724\n",
      "Step 400, Loss: 0.21379123628139496\n",
      "Step 410, Loss: 0.21901600062847137\n",
      "Step 420, Loss: 0.22399216890335083\n",
      "Step 430, Loss: 0.23064254224300385\n",
      "Step 440, Loss: 0.23604553937911987\n",
      "Step 450, Loss: 0.23940099775791168\n",
      "Step 460, Loss: 0.24219635128974915\n",
      "Step 470, Loss: 0.24348527193069458\n",
      "Step 480, Loss: 0.24465663731098175\n",
      "Step 490, Loss: 0.24525968730449677\n",
      "Step 500, Loss: 0.2462351769208908\n",
      "Step 510, Loss: 0.24756893515586853\n",
      "Step 520, Loss: 0.2475181221961975\n",
      "Step 530, Loss: 0.24689826369285583\n",
      "Step 540, Loss: 0.24720808863639832\n",
      "Step 550, Loss: 0.24778182804584503\n",
      "Step 560, Loss: 0.2480098009109497\n",
      "Step 570, Loss: 0.2484193593263626\n",
      "Step 580, Loss: 0.2489054650068283\n",
      "Step 590, Loss: 0.2488856166601181\n",
      "Step 600, Loss: 0.24926429986953735\n",
      "Step 610, Loss: 0.24933527410030365\n",
      "Step 620, Loss: 0.2500758171081543\n",
      "Step 630, Loss: 0.2501973807811737\n",
      "Step 640, Loss: 0.24987661838531494\n",
      "Step 650, Loss: 0.2504463195800781\n",
      "Step 660, Loss: 0.25117358565330505\n",
      "Step 670, Loss: 0.25115320086479187\n",
      "Step 680, Loss: 0.25146162509918213\n",
      "Step 690, Loss: 0.2511464059352875\n",
      "Step 700, Loss: 0.25097450613975525\n",
      "Step 710, Loss: 0.25118470191955566\n",
      "Step 720, Loss: 0.25117918848991394\n",
      "Step 730, Loss: 0.2509269118309021\n",
      "Step 740, Loss: 0.2506513297557831\n",
      "Step 750, Loss: 0.2504589557647705\n",
      "Step 760, Loss: 0.24975962936878204\n",
      "Step 770, Loss: 0.24938634037971497\n",
      "Step 780, Loss: 0.2490023374557495\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-18\n",
      "\n",
      "ðŸš€ Epoch 19/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.039649996906518936\n",
      "Step 10, Loss: 0.04175669327378273\n",
      "Step 20, Loss: 0.042846083641052246\n",
      "Step 30, Loss: 0.044956889003515244\n",
      "Step 40, Loss: 0.04427812620997429\n",
      "Step 50, Loss: 0.04349886253476143\n",
      "Step 60, Loss: 0.04346735402941704\n",
      "Step 70, Loss: 0.042943235486745834\n",
      "Step 80, Loss: 0.04264542832970619\n",
      "Step 90, Loss: 0.04300340637564659\n",
      "Step 100, Loss: 0.04302062466740608\n",
      "Step 110, Loss: 0.042751528322696686\n",
      "Step 120, Loss: 0.0425763800740242\n",
      "Step 130, Loss: 0.044019926339387894\n",
      "Step 140, Loss: 0.04952400177717209\n",
      "Step 150, Loss: 0.05553179234266281\n",
      "Step 160, Loss: 0.06268729269504547\n",
      "Step 170, Loss: 0.07044621556997299\n",
      "Step 180, Loss: 0.07807888835668564\n",
      "Step 190, Loss: 0.08557809889316559\n",
      "Step 200, Loss: 0.09112629294395447\n",
      "Step 210, Loss: 0.0954211875796318\n",
      "Step 220, Loss: 0.1019904613494873\n",
      "Step 230, Loss: 0.10573460161685944\n",
      "Step 240, Loss: 0.11058905720710754\n",
      "Step 250, Loss: 0.11581793427467346\n",
      "Step 260, Loss: 0.12023409456014633\n",
      "Step 270, Loss: 0.12429646402597427\n",
      "Step 280, Loss: 0.1269187480211258\n",
      "Step 290, Loss: 0.1312050074338913\n",
      "Step 300, Loss: 0.1375059336423874\n",
      "Step 310, Loss: 0.14531545341014862\n",
      "Step 320, Loss: 0.15474611520767212\n",
      "Step 330, Loss: 0.16244474053382874\n",
      "Step 340, Loss: 0.17135927081108093\n",
      "Step 350, Loss: 0.17999286949634552\n",
      "Step 360, Loss: 0.18891842663288116\n",
      "Step 370, Loss: 0.1971258968114853\n",
      "Step 380, Loss: 0.2026774138212204\n",
      "Step 390, Loss: 0.20958174765110016\n",
      "Step 400, Loss: 0.2141086608171463\n",
      "Step 410, Loss: 0.2199743539094925\n",
      "Step 420, Loss: 0.2253139466047287\n",
      "Step 430, Loss: 0.23128695785999298\n",
      "Step 440, Loss: 0.2357487827539444\n",
      "Step 450, Loss: 0.23941056430339813\n",
      "Step 460, Loss: 0.24200302362442017\n",
      "Step 470, Loss: 0.24416515231132507\n",
      "Step 480, Loss: 0.2461371272802353\n",
      "Step 490, Loss: 0.24632515013217926\n",
      "Step 500, Loss: 0.2467004507780075\n",
      "Step 510, Loss: 0.2469634711742401\n",
      "Step 520, Loss: 0.246662899851799\n",
      "Step 530, Loss: 0.24672821164131165\n",
      "Step 540, Loss: 0.2465575784444809\n",
      "Step 550, Loss: 0.24705705046653748\n",
      "Step 560, Loss: 0.24753357470035553\n",
      "Step 570, Loss: 0.24794788658618927\n",
      "Step 580, Loss: 0.24860845506191254\n",
      "Step 590, Loss: 0.2487691193819046\n",
      "Step 600, Loss: 0.24894465506076813\n",
      "Step 610, Loss: 0.24936804175376892\n",
      "Step 620, Loss: 0.2501266300678253\n",
      "Step 630, Loss: 0.25046640634536743\n",
      "Step 640, Loss: 0.2509464621543884\n",
      "Step 650, Loss: 0.2507610023021698\n",
      "Step 660, Loss: 0.2508503794670105\n",
      "Step 670, Loss: 0.2508186399936676\n",
      "Step 680, Loss: 0.2509637773036957\n",
      "Step 690, Loss: 0.25060179829597473\n",
      "Step 700, Loss: 0.2506733238697052\n",
      "Step 710, Loss: 0.2507982552051544\n",
      "Step 720, Loss: 0.250933974981308\n",
      "Step 730, Loss: 0.2510024905204773\n",
      "Step 740, Loss: 0.25086331367492676\n",
      "Step 750, Loss: 0.25093260407447815\n",
      "Step 760, Loss: 0.25014084577560425\n",
      "Step 770, Loss: 0.2493714541196823\n",
      "Step 780, Loss: 0.2489805370569229\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-19\n",
      "\n",
      "ðŸš€ Epoch 20/20 - Training GraphAIne_FFN_Model\n",
      "Step 0, Loss: 0.036364078521728516\n",
      "Step 10, Loss: 0.04117633029818535\n",
      "Step 20, Loss: 0.04329954832792282\n",
      "Step 30, Loss: 0.04430941492319107\n",
      "Step 40, Loss: 0.04355094954371452\n",
      "Step 50, Loss: 0.0437990203499794\n",
      "Step 60, Loss: 0.04360130801796913\n",
      "Step 70, Loss: 0.042725324630737305\n",
      "Step 80, Loss: 0.042568668723106384\n",
      "Step 90, Loss: 0.043157514184713364\n",
      "Step 100, Loss: 0.04326571151614189\n",
      "Step 110, Loss: 0.04281477630138397\n",
      "Step 120, Loss: 0.04235423356294632\n",
      "Step 130, Loss: 0.0442618690431118\n",
      "Step 140, Loss: 0.04913991317152977\n",
      "Step 150, Loss: 0.054783374071121216\n",
      "Step 160, Loss: 0.060117874294519424\n",
      "Step 170, Loss: 0.06704743951559067\n",
      "Step 180, Loss: 0.07833968847990036\n",
      "Step 190, Loss: 0.08499818295240402\n",
      "Step 200, Loss: 0.09051621705293655\n",
      "Step 210, Loss: 0.09660686552524567\n",
      "Step 220, Loss: 0.10218750685453415\n",
      "Step 230, Loss: 0.10554810613393784\n",
      "Step 240, Loss: 0.11073048412799835\n",
      "Step 250, Loss: 0.1158812865614891\n",
      "Step 260, Loss: 0.11966737359762192\n",
      "Step 270, Loss: 0.12293968349695206\n",
      "Step 280, Loss: 0.12629848718643188\n",
      "Step 290, Loss: 0.12944597005844116\n",
      "Step 300, Loss: 0.1349513977766037\n",
      "Step 310, Loss: 0.1446932852268219\n",
      "Step 320, Loss: 0.15189827978610992\n",
      "Step 330, Loss: 0.16025453805923462\n",
      "Step 340, Loss: 0.16869531571865082\n",
      "Step 350, Loss: 0.1781858205795288\n",
      "Step 360, Loss: 0.1866571307182312\n",
      "Step 370, Loss: 0.1959773302078247\n",
      "Step 380, Loss: 0.20274707674980164\n",
      "Step 390, Loss: 0.20869296789169312\n",
      "Step 400, Loss: 0.21542498469352722\n",
      "Step 410, Loss: 0.22067488729953766\n",
      "Step 420, Loss: 0.22652719914913177\n",
      "Step 430, Loss: 0.2311752736568451\n",
      "Step 440, Loss: 0.23520298302173615\n",
      "Step 450, Loss: 0.23869653046131134\n",
      "Step 460, Loss: 0.24066846072673798\n",
      "Step 470, Loss: 0.24266213178634644\n",
      "Step 480, Loss: 0.24365423619747162\n",
      "Step 490, Loss: 0.24458153545856476\n",
      "Step 500, Loss: 0.24586407840251923\n",
      "Step 510, Loss: 0.24640898406505585\n",
      "Step 520, Loss: 0.24612906575202942\n",
      "Step 530, Loss: 0.24611207842826843\n",
      "Step 540, Loss: 0.24601517617702484\n",
      "Step 550, Loss: 0.24638953804969788\n",
      "Step 560, Loss: 0.24726086854934692\n",
      "Step 570, Loss: 0.24808530509471893\n",
      "Step 580, Loss: 0.24853529036045074\n",
      "Step 590, Loss: 0.2490856796503067\n",
      "Step 600, Loss: 0.24898923933506012\n",
      "Step 610, Loss: 0.24945183098316193\n",
      "Step 620, Loss: 0.2504073679447174\n",
      "Step 630, Loss: 0.2506244480609894\n",
      "Step 640, Loss: 0.2510692775249481\n",
      "Step 650, Loss: 0.251018226146698\n",
      "Step 660, Loss: 0.2508932948112488\n",
      "Step 670, Loss: 0.2510843575000763\n",
      "Step 680, Loss: 0.25124475359916687\n",
      "Step 690, Loss: 0.25097617506980896\n",
      "Step 700, Loss: 0.2509211301803589\n",
      "Step 710, Loss: 0.25101494789123535\n",
      "Step 720, Loss: 0.25138163566589355\n",
      "Step 730, Loss: 0.2513015568256378\n",
      "Step 740, Loss: 0.2510480284690857\n",
      "Step 750, Loss: 0.25061890482902527\n",
      "Step 760, Loss: 0.2500607669353485\n",
      "Step 770, Loss: 0.2496071457862854\n",
      "Step 780, Loss: 0.24897000193595886\n",
      "ðŸ’¾ Checkpoint saved at ../checkpoints/ffn/ckpt-20\n",
      "\n",
      "âœ… Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "train_ffn(model, dataset, epochs=epochs, learning_rate=learning_rate, checkpoint_path=\"../checkpoints/ffn\")\n",
    "\n",
    "model.save(\"../checkpoints/ffn_model.keras\")  # Save in new Keras format\n",
    "print(\"âœ… Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05244b61-76dc-44c6-b399-6c62eb9287ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0629d02-558a-4ed2-9160-4fbf781ed48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
